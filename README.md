#### **عنوان پروژه:**

**فیلترینگ مشارکتی و سیستم‌های توصیه‌گر با استفاده از دیتاست‌های MovieLens**

#### **مرور پروژه:**

این پروژه بر روی ساخت و ارزیابی یک سیستم توصیه‌گر با استفاده از دیتاست‌های **MovieLens 100K** و **MovieLens 1M** متمرکز است. هدف اصلی، به کارگیری تکنیک‌های یادگیری ماشین، به ویژه **فیلترینگ مشارکتی**، برای پیش‌بینی ترجیحات کاربران و ارائه پیشنهادات شخصی‌سازی‌شده برای فیلم‌ها است. دیتاست شامل امتیازدهی کاربران به فیلم‌ها به همراه اطلاعات جمعیتی است که به تحلیل دقیق‌تر ترجیحات کاربران و بهبود عملکرد الگوریتم‌های توصیه‌گر کمک می‌کند.

#### **بیانیه مشکل:**

با افزایش روزافزون تعداد فیلم‌ها، سیستم‌های توصیه‌گر نقش مهمی در ارائه پیشنهادات شخصی‌سازی‌شده به کاربران دارند. چالش اصلی در پیش‌بینی امتیازهای فیلم‌هایی است که هنوز توسط کاربر امتیازدهی نشده‌اند، که به آن **مشکل شروع سرد (cold-start)** گفته می‌شود. این پروژه به هدف رفع این چالش با استفاده از تکنیک‌های فیلترینگ مشارکتی و ارزیابی مدل‌های مختلف از طریق متریک‌های استاندارد پرداخته است.

#### **اهداف پروژه:**

1. **پیاده‌سازی الگوریتم‌های فیلترینگ مشارکتی**:
    
    - ساخت مدل‌هایی مانند **K-نزدیک‌ترین همسایگان (KNN)** و **Co-Clustering** برای پیش‌بینی امتیازهای کاربران.
    - توسعه مدل توصیه‌گر پیشرفته با استفاده از **ExtKNNCF** برای بهبود عملکرد، به ویژه در مشکلات شروع سرد.
2. **ارزیابی عملکرد مدل‌ها**:
    
    - مقایسه مدل‌های مختلف با استفاده از متریک‌های ارزیابی مانند **MAE** (خطای مطلق میانگین)، **RMSE** (ریشه میانگین مربعات خطا) و **NDCG** (گین تجمعی تخفیف‌خورده نرمال‌شده).
3. **تحلیل نتایج و استخراج بینش‌ها**:
    
    - بررسی عملکرد مدل‌ها بر اساس زیرمجموعه‌های مختلف دیتاست‌های MovieLens 100K و 1M.
    - تحلیل تأثیر اطلاعات جمعیتی کاربران و ژانرهای فیلم‌ها بر دقت پیش‌بینی‌ها.
4. **ارائه بینش‌ها برای کاربردهای دنیای واقعی**:
    
    - ارائه نتایج به نحوی که کاربردهای عملی هر الگوریتم را در سیستم‌های توصیه‌گر واقعی نشان دهد.

#### **توضیحات دیتاست:**

دیتاست‌های **MovieLens 100K** و **MovieLens 1M** شامل امتیازدهی‌های کاربران به فیلم‌ها و اطلاعات جمعیتی کاربران به همراه اطلاعات جزئی درباره فیلم‌ها (مانند عنوان، ژانرها و تاریخ انتشار) هستند.

#### **روش‌شناسی:**

5. **پیش‌پردازش داده‌ها**:
    
    - بارگذاری و تمیزسازی داده‌ها.
    - مدیریت داده‌های گمشده، حذف ورودی‌های تکراری، و پیش‌پردازش اطلاعات جمعیتی.
    - تقسیم داده‌ها به مجموعه‌های **آموزشی** و **تست** برای ارزیابی مدل‌ها.
6. **پیاده‌سازی الگوریتم‌ها**:
    
    - **KNN (K-نزدیک‌ترین همسایگان)**: یافتن کاربران یا فیلم‌های مشابه برای پیش‌بینی امتیازهای فیلم‌های ناشناخته.
    - **Co-Clustering**: خوشه‌بندی همزمان کاربران و فیلم‌ها برای بهبود دقت توصیه‌ها.
    - **ExtKNNCF**: یک نسخه پیشرفته از الگوریتم KNN برای بهبود عملکرد در مشکلات شروع سرد.
7. **ارزیابی مدل‌ها**:
    
    - استفاده از متریک‌های ارزیابی مانند **MAE**، **RMSE** و **NDCG** برای اندازه‌گیری عملکرد هر مدل.

- مقایسه مدل‌ها بر اساس توانایی آن‌ها در پیش‌بینی دقیق امتیازها و پردازش فیلم‌های ناشناخته.

8. **تحلیل و نتایج**:
    - تحلیل نتایج به دست آمده از مدل‌های مختلف.
    - تجزیه و تحلیل تأثیر اطلاعات جمعیتی کاربران و ژانرها بر دقت پیش‌بینی‌ها.
  
###  پیاده‌سازی پروژه

### **مرحله 1: دانلود و آماده‌سازی داده‌ها**
#### **شرح کار:**
در این مرحله، بایم داده‌های مورد نیاز را دانلود کرده و آماده‌سازی کنیم. دو مجموعه داده MovieLens 100K و MovieLens 1M مورد استفاده قرار خواهد گرفت.

#### **فرمان‌ها و دستورات:**
1. **دانلود داده‌ها:**
   - از لینک زیر داده‌ها را دانلود کنیم:
     ```
     wget http://files.grouplens.org/datasets/movielens/ml-100k.zip
     wget http://files.grouplens.org/datasets/movielens/ml-1m.zip
     ```

2. **استخراج فایل‌ها:**
   - فایل‌های فشرده را با استفاده از دستور `unzip` استخراج کنیم:
     ```bash
     unzip ml-100k.zip
     unzip ml-1m.zip
     ```

3. **بررسی فایل‌ها:**
   - مطمئن شویم فایل‌های لازم (مثل `u.data` برای MovieLens 100K و `ratings.dat` برای MovieLens 1M) در پوشه‌های استخراج‌شده وجود دارند:
     ```bash
     ls ml-100k/
     ls ml-1m/
     ```

---

### **مرحله 2: تنظیم محیط برنامه‌نویسی**
#### **شرح کار:**
برای اجرای این پروژه، نیاز به نصب کتابخانه‌های Python داریم. در این مرحله، یک محیط مجازی Python ایجاد و کتابخانه‌های لازم را نصب خواهیم کرد.

#### **فرمان‌ها و دستورات:**
4. **ایجاد محیط مجازی:**
   ```bash
   python -m venv env
   source env/bin/activate
   ```

5. **نصب کتابخانه‌ها:**
   ```bash
   pip install numpy pandas scikit-learn matplotlib seaborn
   ```

---

### **مرحله 3: خواندن و پیش‌پردازش داده‌ها**

در این مرحله، داده‌ها را با استفاده از کتابخانه Pandas خوانده و پیش‌پردازش می‌کنیم. همچنین، ستون‌های لازم را اضافه کرده و داده‌ها را به دو بخش آموزش و آزمایش تقسیم می‌کنیم.

### **مرحله 4: پیاده‌سازی الگوریتم‌های توصیه‌دهنده**
در این مرحله، سه نوع الگوریتم توصیه‌دهنده را پیاده‌سازی می‌کنیم:
6. **KNN (K-Nearest Neighbors):** برای یافتن کاربران یا آیتم‌های مشابه.
7. **Co-Clustering:** برای خوشه‌بندی همزمان کاربران و آیتم‌ها.
8. **ExtKNNCF:** یک نسخه پیشرفته‌تر از KNN برای حل مشکل Cold Start.

---

### **مرحله 5: ارزیابی عملکرد مدل‌ها**
در این مرحله، مدل‌های پیاده‌سازی‌شده را با استفاده از معیارهای ارزیابی مانند MAE، RMSE و NDCG ارزیابی می‌کنیم.

---

### **مرحله 6: تحلیل نتایج و ارائه گزارش**
در این مرحله، نتایج حاصل از مدل‌ها را تحلیل کرده و بهترین مدل را تعیین می‌کنیم. نتایج را به صورت تصویری نیز نمایش می‌دهیم.

---
### **گزارش پروژه سیستم توصیه‌دهنده MovieLens**

#### **چکیده**
این پروژه به پیاده‌سازی و ارزیابی سیستم‌های توصیه‌دهنده برای داده‌های MovieLens می‌پردازد. سه الگوریتم مختلف شامل **Co-Clustering**, **K-Nearest Neighbors (KNN)**، و **Extended KNN Collaborative Filtering (ExtKNNCF)** در این پروژه پیاده‌سازی شده‌اند. هدف از این پروژه مقایسه عملکرد این الگوریتم‌ها با استفاده از معیارهای ارزیابی مانند **MAE**, **RMSE**، و **NDCG** است.

---

### **1. فایل‌های پروژه و توضیحات آن‌ها**

#### **1.1. `data_preprocessing.py`**
این فایل مسئول پیش‌پردازش داده‌های خام MovieLens است. وظایف اصلی آن شامل:
- بارگیری داده‌های خام (`u.data`) و تعریف ستون‌های `user_id`, `item_id`, `rating`, و `timestamp`.
- اضافه کردن یک ستون جدید به نام `recommended` که نشان‌دهنده توصیه‌پذیری یک آیتم است (اگر امتیاز برابر یا بیشتر از 3 باشد، مقدار آن 1 درغیر این صورت 0).
- تقسیم داده‌ها به مجموعه‌های آموزشی و آزمایشی با نسبت 80% و 20%.
- ذخیره مجموعه‌های آموزشی و آزمایشی به عنوان فایل‌های CSV (`train_data.csv` و `test_data.csv`).

---

#### **1.2. `coclustering_recommendation_system.py`**
این فایل الگوریتم **Co-Clustering** را پیاده‌سازی می‌کند. مراحل اصلی شامل:
- بارگیری مجموعه داده آموزشی (`train_data.csv`) و ایجاد ماتریس کاربر-آیتم.
- استفاده از الگوریتم **Spectral Co-Clustering** برای خوشه‌بندی کاربران و آیتم‌ها.
- ذخیره نتایج خوشه‌بندی به عنوان فایل CSV (`coclustering_predictions.csv`).
- تولید پیش‌بینی‌ها برای داده‌های آزمایشی بر اساس خوشه‌بندی.

---

#### **1.3. `knn_recommendation_system.py`**
این فایل الگوریتم **K-Nearest Neighbors (KNN)** را پیاده‌سازی می‌کند. مراحل اصلی شامل:
- بارگیری مجموعه داده آموزشی و ایجاد ماتریس کاربر-آیتم.
- استفاده از کلاس `NearestNeighbors` از کتابخانه `scikit-learn` برای محاسبه شباهت بین کاربران بر اساس معیار فاصله کوسین.
- پیدا کردن نزدیک‌ترین همسایگان برای هر کاربر.
- تولید پیش‌بینی‌ها برای داده‌های آزمایشی و ذخیره آن‌ها به عنوان فایل CSV (`knn_predictions.csv`).

---

#### **1.4. `ext_knn_cf_recommendation_system.py`**
این فایل الگوریتم **Extended KNN Collaborative Filtering (ExtKNNCF)** را پیاده‌سازی می‌کند. مراحل اصلی شامل:
- ادغام ویژگی‌های کاربران (`user_features.csv`) و آیتم‌ها (`item_features.csv`) با داده‌های رتبه‌بندی.
- ایجاد یک ماتریس ویژگی گسترده که شامل رتبه‌بندی‌ها و ویژگی‌های اضافی است.
- استفاده از KNN برای محاسبه شباهت بین کاربران بر اساس ماتریس ویژگی گسترده.
- تولید پیش‌بینی‌ها برای داده‌های آزمایشی و ذخیره آن‌ها به عنوان فایل CSV (`ext_knn_cf_predictions.csv`).

---

#### **1.5. `evaluate_recommendation_models.py`**
این فایل مسئول ارزیابی عملکرد سه الگوریتم پیاده‌سازی‌شده است. وظایف اصلی شامل:
- بارگیری داده‌های آزمایشی (`test_data.csv`) و پیش‌بینی‌های تولید شده توسط هر الگوریتم.
- محاسبه معیارهای ارزیابی **MAE**, **RMSE**, و **NDCG** برای هر الگوریتم.
- چاپ نتایج ارزیابی در خروجی کنسول.

---

#### **1.6. `visualize_results.py`**
این فایل نتایج ارزیابی را به صورت تصویری نمایش می‌دهد. وظایف اصلی شامل:
- ایجاد نمودار میله‌ای (Bar Chart) برای مقایسه **MAE** و **RMSE** بین الگوریتم‌ها.
- ایجاد نمودار خطی (Line Chart) برای نمایش تغییرات نتایج بر اساس معیارهای مختلف.
- ذخیره نمودارها به صورت فایل تصویری برای گزارش‌نویسی.

#### **1.8. `item_features.csv` و `user_features.csv`**
این فایل‌ها شامل ویژگی‌های آیتم‌ها و کاربران هستند. 
- `item_features.csv`: شامل ویژگی‌های فیلم‌ها مانند ژانر.
- `user_features.csv`: شامل ویژگی‌های کاربران مانند سن، جنسیت، و شغل.

---

#### **1.9. `ratings_data.csv`, `train_data.csv`, و `test_data.csv`**
- `ratings_data.csv`: شامل تمام داده‌های رتبه‌بندی قبل از تقسیم‌بندی.
- `train_data.csv`: مجموعه داده آموزشی.
- `test_data.csv`: مجموعه داده آزمایشی.

---

#### **1.10. `coclustering_predictions.csv`, `knn_predictions.csv`, و `ext_knn_cf_predictions.csv`**
این فایل‌ها شامل پیش‌بینی‌های تولید شده توسط هر یک از الگوریتم‌ها برای داده‌های آزمایشی هستند.

---

#### **1.11. `user_item_matrix_100k.csv`**
این فایل ماتریس کاربر-آیتم را ذخیره می‌کند که در بسیاری از فایل‌ها برای آموزش مدل‌ها استفاده می‌شود.

---

### **2. رویکرد پیاده‌سازی**

#### **2.1. پیش‌پردازش داده‌ها**
پیش‌پردازش داده‌ها در دو مرحله انجام شده است:
1. **تقسیم‌بندی داده‌ها**: داده‌های خام MovieLens (`u.data`) بارگیری شده و به دو مجموعه آموزشی و آزمایشی تقسیم شده‌اند.
2. **ادغام ویژگی‌ها**: ویژگی‌های کاربران و آیتم‌ها از فایل‌های جداگانه (`user_features.csv` و `item_features.csv`) بارگیری شده و به داده‌های رتبه‌بندی ادغام شده‌اند.

#### **2.2. پیاده‌سازی الگوریتم‌ها**
سه الگوریتم مختلف پیاده‌سازی شده‌اند:
1. **Co-Clustering**: این الگوریتم از خوشه‌بندی همزمان کاربران و آیتم‌ها برای تولید پیش‌بینی‌ها استفاده می‌کند.
2. **KNN**: این الگوریتم شباهت بین کاربران را بر اساس فاصله کوسین محاسبه می‌کند و پیش‌بینی‌ها را بر اساس نزدیک‌ترین همسایگان تولید می‌کند.
3. **ExtKNNCF**: این الگوریتم از ویژگی‌های اضافی کاربران و آیتم‌ها برای بهبود عملکرد KNN استفاده می‌کند.

#### **2.3. ارزیابی مدل‌ها**
نتایج هر سه الگوریتم با استفاده از معیارهای ارزیابی زیر مقایسه شده‌اند:
- **MAE (Mean Absolute Error)**: اندازه‌گیری خطای مطلق میانگین.
- **RMSE (Root Mean Squared Error)**: اندازه‌گیری جذر میانگین مربعات خطا.
- **NDCG (Normalized Discounted Cumulative Gain)**: اندازه‌گیری کیفیت ترتیب‌بندی توصیه‌ها.

#### **2.4. ترسیم نتایج**
نتایج ارزیابی به صورت نمودارهای میله‌ای و خطی ترسیم شده‌اند تا مقایسه بصری ساده‌تری از عملکرد مدل‌ها فراهم شود.

---

### **3. نتایج و تحلیل**

#### **3.1. مقایسه معیارهای ارزیابی**
نتایج نشان می‌دهد که الگوریتم **ExtKNNCF** در کلیه معیارهای ارزیابی بهترین عملکرد را داشته است. این به دلیل استفاده از ویژگی‌های اضافی کاربران و آیتم‌ها است که به بهبود دقت پیش‌بینی‌ها کمک می‌کند.

#### **3.2. تحلیل نتایج**
- **Co-Clustering**: این الگوریتم برای داده‌هایی که ساختار خوشه‌ای قابل‌تشخیص دارند مناسب است، اما در مقایسه با KNN و ExtKNNCF، عملکرد ضعیف‌تری دارد.
- **KNN**: این الگوریتم به طور کلی عملکرد قابل قبولی دارد، اما در مقایسه با ExtKNNCF، دقت پیش‌بینی‌ها کمتر است.
- **ExtKNNCF**: این الگوریتم با استفاده از ویژگی‌های اضافی، بهبود قابل‌توجهی در دقت پیش‌بینی‌ها به دست آورده است.

---

### **4. نتیجه‌گیری**

این پروژه سه الگوریتم مختلف سیستم توصیه‌دهنده را پیاده‌سازی و ارزیابی کرده است. نتایج نشان می‌دهد که استفاده از ویژگی‌های اضافی (مانند ژانر فیلم‌ها و ویژگی‌های دموگرافیک کاربران) می‌تواند به بهبود عملکرد سیستم توصیه‌دهنده کمک کند. الگوریتم **ExtKNNCF** به عنوان بهترین مدل شناسایی شد و برای کاربردهای واقعی پیشنهاد می‌شود.

### **4. خروجی کد**
1. پیش‌پردازش داده‌ها
ابتدا داده‌ها را پیش‌پردازش می کنیم تا مجموعه داده‌های آموزشی و آزمایشی تولید شوند:

python3 data_preprocessing.py
 خروجی
Dataset loaded successfully.
Preprocessing complete: 'recommended' column added.
Data split into training (80000 samples) and testing (20000 samples) sets.
Training data saved to train_data.csv.
Testing data saved to test_data.csv.

2. آموزش مدل Co-Clustering
سیستم توصیه‌دهنده Co-Clustering را آموزش می دهیم:


python3 coclustering_recommendation_system.py
خروجی :
python3 coclustering_recommendation_system.py
Training data loaded successfully.
User-item matrix created successfully.
Co-Clustering model trained successfully.
Clusters extracted successfully.
User clusters: [2 3 0 0 1 2 1 1 2 2 1 1 1 2 3 1 3 2 2 1 1 1 2 1 2 3 3 1 0 1 2 3 0 0 0 0 1
 1 0 0 2 1 1 1 3 0 0 2 1 3 1 3 3 3 3 1 3 2 2 2 0 2 3 1 2 3 3 3 3 1 2 2 2 0
 3 2 2 3 3 2 3 2 1 3 2 0 1 0 3 2 2 1 3 1 1 2 2 2 3 0 3 1 3 3 0 2 0 3 1 1 0
 0 3 2 2 0 3 1 1 3 2 2 2 1 1 0 1 1 0 1 3 2 0 0 1 3 1 2 3 0 3 1 0 2 1 0 0 1
 0 3 2 1 1 2 0 2 3 1 3 3 2 3 0 3 1 0 2 3 2 0 0 2 0 1 1 3 1 1 0 1 3 3 1 2 2
 1 2 1 2 3 0 3 1 1 1 2 1 1 3 1 2 2 3 0 0 4 1 1 3 1 1 2 1 2 1 1 1 2 2 0 1 1
 3 1 2 2 3 1 0 1 3 2 2 2 2 1 2 3 2 0 0 3 2 1 3 1 3 1 1 1 3 3 1 1 1 1 2 0 1
 4 0 1 1 2 3 3 1 1 2 1 2 2 0 3 1 1 3 0 1 1 0 0 1 0 2 1 3 2 3 1 1 2 1 3 1 2
 1 2 2 3 1 0 1 0 2 3 1 2 0 3 1 2 1 1 2 2 0 1 0 1 2 2 3 3 2 1 2 1 2 1 2 1 2
 2 0 1 1 2 2 1 0 2 2 2 3 1 1 3 3 2 0 1 0 2 0 0 3 2 3 2 2 0 1 0 3 1 1 1 0 2
 1 1 1 1 1 2 1 1 2 2 2 2 2 0 2 3 2 1 2 3 2 2 1 1 1 3 2 2 1 0 2 3 3 0 1 2 1
 0 2 0 1 2 3 0 2 1 1 0 2 2 2 3 0 3 1 2 0 0 1 3 0 3 2 3 1 1 2 3 3 0 3 1 0 0
 3 0 3 0 2 1 0 2 1 2 1 2 1 2 3 3 0 0 3 0 2 0 3 2 2 3 1 1 3 2 0 1 1 1 1 2 2
 0 1 1 0 3 1 1 0 3 2 2 1 2 1 1 1 2 2 2 3 0 2 1 1 1 0 2 0 0 0 1 3 2 0 2 3 3
 4 3 1 2 2 2 3 3 2 1 0 2 0 1 1 3 2 1 2 1 2 3 1 1 2 0 1 1 0 3 3 3 1 3 2 1 3
 2 0 3 1 3 2 1 1 3 2 2 2 2 3 0 2 3 2 0 2 3 1 0 1 3 3 3 2 1 2 1 0 1 0 3 2 2
 1 3 3 0 3 0 3 1 1 3 1 1 2 1 2 2 0 2 0 3 2 3 2 0 2 1 1 1 1 1 2 3 2 0 1 0 1
 3 0 1 1 3 0 3 3 1 2 1 2 1 1 3 2 0 1 1 3 1 0 0 1 1 2 0 3 2 2 1 2 3 3 2 3 2
 2 0 2 2 1 3 0 3 2 1 3 3 1 3 0 1 0 1 0 2 0 4 3 1 2 3 1 2 0 0 3 2 3 1 3 0 3
 2 1 3 2 3 1 2 2 1 4 3 1 2 3 3 1 0 0 3 2 0 3 3 1 3 0 3 2 0 3 2 3 3 2 1 1 0
 1 3 3 2 2 1 2 2 1 0 1 0 2 3 0 1 1 2 3 1 3 3 2 3 2 2 2 3 3 3 2 0 2 1 0 1 2
 1 3 2 2 0 0 0 2 1 0 1 3 1 0 3 3 3 1 1 0 1 2 3 0 1 0 1 1 2 1 0 0 0 0 0 0 1
 1 0 3 0 0 0 3 1 1 0 3 1 0 2 2 1 1 0 2 3 2 2 3 2 3 2 0 0 1 1 4 1 1 2 1 1 1
 3 0 2 2 0 3 0 3 2 2 1 0 1 3 0 2 1 3 2 0 3 0 2 2 2 2 2 3 1 1 1 2 2 1 1 1 2
 2 2 3 1 3 2 3 1 1 0 1 2 1 2 2 1 3 3 3 2 2 3 2 2 2 1 0 1 3 2 3 0 1 1 3 2 1
 0 1 0 2 3 3 2 1 2 3 3 3 3 3 2 3 2 1]
Item clusters: [3 1 3 ... 4 4 1]
Test data loaded successfully.
Co-Clustering predictions generated successfully.
Co-Clustering predictions saved to 'coclustering_predictions.csv'.

3. آموزش مدل KNN
سیستم توصیه‌دهنده KNN را آموزش می دهیم:

python3 knn_recommendation_system.py
خروجی :

Training data loaded successfully.
User-item matrix created successfully.
KNN model trained successfully.
Top 5 similar users for user 1: [1, 514, 268, 293, 457]
Test data loaded successfully.
KNN predictions generated successfully.
KNN predictions saved to knn_predictions.csv.
4. آموزش مدل ExtKNNCF
سیستم توصیه‌دهنده ExtKNNCF را آموزش می دهیم:

python3 ext_knn_cf_recommendation_system.py
خروجی :
Datasets loaded successfully.
Data merged with user and item features successfully.
Extended feature matrix created successfully.
ExtKNNCF model trained successfully.
ExtKNNCF predictions generated successfully.
ExtKNNCF predictions saved to ext_knn_cf_predictions.csv.
5. ارزیابی مدل‌ها
عملکرد سه مدل را با استفاده از معیارهای MAE، RMSE، و NDCG ارزیابی می کنیم:


python3 evaluate_recommendation_models.py
خروجی :


Coclustering Model - MAE: 0.8500, RMSE: 1.1200, NDCG: 0.7500
KNN Model - MAE: 0.7800, RMSE: 1.0500, NDCG: 0.8000
ExtKNNCF Model - MAE: 0.7200, RMSE: 0.9800, NDCG: 0.8500

Final Evaluation Results:
Coclustering - MAE: 0.8500, RMSE: 1.1200, NDCG: 0.7500
KNN - MAE: 0.7800, RMSE: 1.0500, NDCG: 0.8000
ExtKNNCF - MAE: 0.7200, RMSE: 0.9800, NDCG: 0.8500
6. ترسیم نتایج
نمودار مقایسه‌ای عملکرد مدل‌ها را ترسیم کنید:خروجی مورد انتظار:

یک نمودار میله‌ای (Bar Chart) به صورت تصویری نمایش داده می‌شود که مقایسه MAE و RMSE مدل‌ها را نشان می‌دهد.

### الگوریتمی برای بهبود سیستم توصیه‌گر مبتنی بر فیلترینگ همکاری

هدف این الگوریتم، بهبود دقت پیش‌بینی و مدیریت داده‌های پراکنده در سیستم توصیه‌گر است. این سیستم از داده‌های MovieLens-100K و MovieLens-1M برای شبیه‌سازی به‌کارگیری روش‌های فیلترینگ همکاری و دیگر تکنیک‌های پیشرفته استفاده می‌کند. مراحل این الگوریتم شامل فرآیندهای پیش‌پردازش، بهبود مدل، ترکیب مدل‌ها، و ارزیابی عملکرد است. 

---

#### گام 1: پردازش داده‌ها و مهندسی ویژگی‌ها

**1.1 جمع‌آوری و پاک‌سازی داده‌ها**

- **دریافت داده‌ها**: داده‌های MovieLens-100K و MovieLens-1M را دریافت کنید. این داده‌ها شامل نظرات کاربران در مورد فیلم‌ها و ویژگی‌های دیگر است.
- **پاک‌سازی داده‌ها**:
  - حذف داده‌های تکراری.
  - پرکردن یا حذف مقادیر گمشده.
  - حذف کاربرانی که تعداد نظرات کمی دارند تا به داده‌های مهم‌تر توجه شود.

**1.2 تحلیل الگوهای تعامل کاربر-آیتم**

- **استخراج قوانین انجمنی**: 
  - شناسایی آیتم‌هایی که معمولاً توسط کاربران مشابه ارزیابی می‌شوند. برای این کار می‌توانید از تکنیک‌های **Apriori** یا **FP-Growth** استفاده می کنیم .
  
- **تحلیل بر اساس گراف**:
  - شبکه‌سازی روابط کاربر-آیتم به‌صورت گراف و شناسایی خوشه‌های مرتبط.
  - به‌کارگیری الگوریتم‌هایی مانند **PageRank** یا **HITS** برای شناسایی کاربران و آیتم‌های تأثیرگذار.

**1.3 تکنیک‌های تجمیع پیشرفته**

- **میانگین‌های وزنی**:
  برای هر ارزیابی کاربر از وزن‌های متفاوت استفاده می کنیم:
  \[
  \text{Weighted Rating}(u, i) = w_{\text{recency}} \cdot \text{Rating}(u, i) + w_{\text{activity}} \cdot \text{Activity}(u) + w_{\text{popularity}} \cdot \text{Popularity}(i)
  \]
  در اینجا وزن‌ها به عواملی مثل تازگی ارزیابی (Recency)، فعالیت کاربر (Activity) و محبوبیت آیتم (Popularity) بستگی دارد.
  
- **تجمیع مبتنی بر خوشه‌بندی**:
  کاربران یا آیتم‌ها را به خوشه‌هایی تقسیم کنید و از ویژگی‌های سطح خوشه به‌عنوان ورودی به مدل استفاده کنید. این خوشه‌ها را می‌توان با **K-Means** یا **DBSCAN** استخراج کرد.

---

#### گام 2: بهبود مدل

**2.1 استفاده از تفکیک ماتریس (Matrix Factorization)**

- **مدل‌سازی روابط پنهانی**:
  - استفاده از **SVD** (تفکیک مقدار منفرد) برای تجزیه ماتریس کاربر-آیتم:
  \[
  R = U \cdot \Sigma \cdot V^T
  \]
  در اینجا، \( R \) ماتریس کاربر-آیتم است، \( U \) ماتریس ویژگی‌های کاربران، \( \Sigma \) ماتریس مقادیر خاص و \( V^T \) ماتریس ویژگی‌های آیتم‌ها هستند.

- **پیاده‌سازی SVD**:
  این روش می‌تواند با استفاده از **Stochastic Gradient Descent** (SGD) یا **Alternating Least Squares** (ALS) بهینه‌سازی شود.

**2.2 فیلترینگ همکاری عصبی (Neural Collaborative Filtering)**

- **مدل‌سازی تعاملات غیرخطی**:
  از شبکه‌های عصبی برای مدل‌سازی روابط پیچیده بین کاربران و آیتم‌ها استفاده کنید. این شبکه‌ها می‌توانند از لایه‌های **Fully Connected** استفاده کرده و ویژگی‌های پنهانی غیرخطی را شبیه‌سازی کنند.
  
- **پیاده‌سازی NeuMF**:
  مدل **Neural Matrix Factorization (NeuMF)** از ترکیب فیلترینگ مبتنی بر ماتریس و شبکه عصبی استفاده می‌کند. این مدل شامل دو بخش است: 
  1. **MF (Matrix Factorization)**: برای شبیه‌سازی روابط خطی.
  2. **MLP (Multilayer Perceptron)**: برای شبیه‌سازی روابط غیرخطی.
  \[
  \hat{r}_{ui} = f_{\text{NeuMF}}(u, i) = \sigma(W_f \cdot [h_u, h_i])
  \]
  در اینجا، \( h_u \) و \( h_i \) ویژگی‌های پنهانی کاربران و آیتم‌ها هستند.

**2.3 استفاده از KNN تطبیقی (Adaptive KNN)**

- **مدل‌سازی تطبیقی KNN**:
  از الگوریتم‌های **K-نزدیک‌ترین همسایه (KNN)** به‌صورت تطبیقی استفاده کنید. در اینجا، فاصله بین کاربر و آیتم بر اساس ویژگی‌های خاص مانند میزان تعاملات یا فعالیت‌های قبلی محاسبه می‌شود. به‌طور معمول از **متریک فاصله Minkowski** یا **Cosine Similarity** استفاده می‌شود.

---

#### گام 3: روش‌های ترکیبی

**3.1 ترکیب فیلترینگ همکاری و فیلترینگ مبتنی بر محتوا**

- **مدل ترکیبی**:
  - ترکیب فیلترینگ همکاری با فیلترینگ مبتنی بر محتوا می‌تواند دقت سیستم را به‌ویژه در مواقعی که اطلاعات کاربر یا آیتم کافی نیست، افزایش دهد. از ویژگی‌های محتوا مانند ژانر، سال تولید، و ویژگی‌های دیگر آیتم‌ها برای تکمیل نتایج استفاده می کنیم.
  
- فرمول ترکیبی:
  \[
  \hat{r}_{ui} = \alpha \cdot \hat{r}_{ui}^{\text{collaborative}} + (1 - \alpha) \cdot \hat{r}_{ui}^{\text{content-based}}
  \]
  در اینجا، \( \alpha \) وزن فیلترینگ همکاری است که معمولاً بین 0 و 1 قرار دارد.

**3.2 استفاده از اطلاعات ژانر و اعتماد**

- **مدل‌سازی مبتنی بر ژانر و اعتماد**:
  - استفاده از ویژگی‌های ژانر برای بهبود پیش‌بینی‌ها به‌ویژه در مواجهه با مشکل **شروع سرد**.
  - **اعتماد** به عنوان یک معیار برای تصمیم‌گیری در مورد میزان اعتبار توصیه‌ها. به‌طور مثال، کاربران با فعالیت بیشتر یا امتیازدهی‌های معتبرتر، تأثیر بیشتری بر سیستم دارند.

---

#### گام 4: ارزیابی و بهینه‌سازی

**4.1 ارزیابی مدل**

- **معیارهای ارزیابی**:
  برای ارزیابی عملکرد مدل از معیارهای زیر استفاده می کنیم:
  \[
  \text{RMSE} = \sqrt{\frac{1}{N} \sum_{(u,i) \in T} (\hat{r}_{ui} - r_{ui})^2}
  \]
  \[
  \text{MAE} = \frac{1}{N} \sum_{(u,i) \in T} |\hat{r}_{ui} - r_{ui}|
  \]
  - **MAP** (Mean Average Precision) و **NDCG** (Normalized Discounted Cumulative Gain) برای ارزیابی دقت رتبه‌بندی.

- **ارزیابی تنوع و نوآوری**:
  از معیارهایی مانند **Diversity** (تنوع پیشنهادات) و **Novelty** (جدت) برای ارزیابی کیفیت پیشنهادات استفاده می کنیم.

**4.2 بهینه‌سازی هایپرپارامترها**

- **تنظیم هایپرپارامترها**:
  از تکنیک‌های بهینه‌سازی مانند **Grid Search** یا **Random Search** برای تنظیم هایپرپارامترها استفاده کنید. پارامترهایی مانند **نرخ یادگیری (learning rate)**، **تعداد لایه‌ها** و **ابعاد ویژگی‌های پنهانی** از جمله مهم‌ترین هایپرپارامترها هستند.

**4.3 استفاده از تکنیک‌های پیشرفته**

- **یادگیری انتقالی (Transfer Learning)**:
  استفاده از مدل‌های پیش‌آموزش‌دیده بر روی داده‌های مشابه برای بهبود عملکرد سیستم، به‌ویژه در هنگام روبرو شدن با داده‌های جدید.

- **یادگیری متا (Meta-Learning)**:
  استفاده از الگوریتم‌های یادگیری متا برای کمک به مدل در تطبیق سریع با کاربران یا آیتم‌های جدید.

---

















 
